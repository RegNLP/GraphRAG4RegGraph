{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "machine_shape": "hm",
      "gpuType": "L4",
      "mount_file_id": "1lzNmqb2Ux02gatTn-9-wtfBRIFSdR_an",
      "authorship_tag": "ABX9TyMjCRgHkDexAnnsfPxIqguu",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "fcfdc15a85fa450fbbb8211e8d9c986d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_58879b517248413b95043db65d266249",
              "IPY_MODEL_f1233bd0789342a68953ae685b79de25",
              "IPY_MODEL_1f396c2fe6fd46bf9717528bc67fef36"
            ],
            "layout": "IPY_MODEL_7009eb9f84d14499a1323477c85ed03e"
          }
        },
        "58879b517248413b95043db65d266249": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_a80f5490bd6649ea84f8cf3b1ab8b6da",
            "placeholder": "​",
            "style": "IPY_MODEL_b2186b45675249d79c67fd58f7b5f3fb",
            "value": "Batches: 100%"
          }
        },
        "f1233bd0789342a68953ae685b79de25": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_aa2b708762b644a9bf8aec34d085938e",
            "max": 859,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_4136b93e284740c585420be88c438b78",
            "value": 859
          }
        },
        "1f396c2fe6fd46bf9717528bc67fef36": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_13683102556e4754821c22b618864423",
            "placeholder": "​",
            "style": "IPY_MODEL_472df0d3604d4a09aba723fa4e042e1f",
            "value": " 859/859 [01:49&lt;00:00, 49.47it/s]"
          }
        },
        "7009eb9f84d14499a1323477c85ed03e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a80f5490bd6649ea84f8cf3b1ab8b6da": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "b2186b45675249d79c67fd58f7b5f3fb": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "aa2b708762b644a9bf8aec34d085938e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "4136b93e284740c585420be88c438b78": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "13683102556e4754821c22b618864423": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "472df0d3604d4a09aba723fa4e042e1f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "6545a3252b184ca0894659a0719005b5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_4a6a062aff6f4739bedf0b131fdc36b0",
              "IPY_MODEL_803d566254d94e2ab06df2e07bbb3032",
              "IPY_MODEL_e50822d6695d48b698ad613aec637019"
            ],
            "layout": "IPY_MODEL_c63eb1b6e9ab433cb55b44559121540a"
          }
        },
        "4a6a062aff6f4739bedf0b131fdc36b0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_303d8886154b4c078813c15b07fb0b9f",
            "placeholder": "​",
            "style": "IPY_MODEL_8dbfefd9bf8b4d67abf08a472679e472",
            "value": "Batches: 100%"
          }
        },
        "803d566254d94e2ab06df2e07bbb3032": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_30806cb2848641f5bd17f6858d6522ea",
            "max": 859,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_d32231715d2c43e8b62122dc9ccce0f7",
            "value": 859
          }
        },
        "e50822d6695d48b698ad613aec637019": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_5033a65b5bf94691b4a6e4562502f7de",
            "placeholder": "​",
            "style": "IPY_MODEL_4a889416aaf24d2ca21d4ea7f3523174",
            "value": " 859/859 [00:37&lt;00:00, 75.06it/s]"
          }
        },
        "c63eb1b6e9ab433cb55b44559121540a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "303d8886154b4c078813c15b07fb0b9f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "8dbfefd9bf8b4d67abf08a472679e472": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "30806cb2848641f5bd17f6858d6522ea": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "d32231715d2c43e8b62122dc9ccce0f7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "5033a65b5bf94691b4a6e4562502f7de": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "4a889416aaf24d2ca21d4ea7f3523174": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "4e47384220d145edab7ef0eff52174af": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_e22bb1a0d6f5445a9a9792f56d1982e3",
              "IPY_MODEL_ac796a4aa6fa494d854dce86cac10998",
              "IPY_MODEL_36e2268747ee4d56ba47c82e1ab9078f"
            ],
            "layout": "IPY_MODEL_6a118a58fea64265af1eadd574744796"
          }
        },
        "e22bb1a0d6f5445a9a9792f56d1982e3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_5ebc4bee0ac8439185c6270df4d7059d",
            "placeholder": "​",
            "style": "IPY_MODEL_a543617fb92a4b349762f46ce720648a",
            "value": "Batches: 100%"
          }
        },
        "ac796a4aa6fa494d854dce86cac10998": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_b0e7c20d727147b38fe2715f31b7eb4f",
            "max": 859,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_6ef061541e99459caadea1a19240c318",
            "value": 859
          }
        },
        "36e2268747ee4d56ba47c82e1ab9078f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_90da97e95ca549cda9075939b9049abb",
            "placeholder": "​",
            "style": "IPY_MODEL_6ac61483683a49be86fafb99d557b444",
            "value": " 859/859 [01:51&lt;00:00, 49.47it/s]"
          }
        },
        "6a118a58fea64265af1eadd574744796": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "5ebc4bee0ac8439185c6270df4d7059d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a543617fb92a4b349762f46ce720648a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "b0e7c20d727147b38fe2715f31b7eb4f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "6ef061541e99459caadea1a19240c318": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "90da97e95ca549cda9075939b9049abb": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "6ac61483683a49be86fafb99d557b444": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/RegNLP/GraphRAG4RegGraph/blob/main/3_GraphRAG_Hybrid_Pipeline_with_Fine_Tuned_Models.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Install the latest compatible versions of the necessary libraries\n",
        "#!pip install -q sentence-transformers transformers datasets pytrec-eval rank_bm25"
      ],
      "metadata": {
        "id": "ZkbZGRsAXvkX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import json\n",
        "import torch\n",
        "import pickle\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import pytrec_eval\n",
        "import networkx as nx\n",
        "from sentence_transformers import SentenceTransformer, util\n",
        "from transformers import AutoTokenizer, AutoModelForSequenceClassification\n",
        "from tqdm import tqdm\n",
        "from rank_bm25 import BM25Okapi\n",
        "\n",
        "# --- Configuration ---\n",
        "# Path to the main data folder\n",
        "data_folder = \"/content/drive/MyDrive/Colab Notebooks/modeldatalocation\"\n",
        "\n",
        "# --- Models to Evaluate ---\n",
        "# Path to the folder containing all your fine-tuned embedding models (Retrievers)\n",
        "finetuned_embedding_models_folder = os.path.join(data_folder, \"finetuned_embedding_models_hard_neg\")\n",
        "embedding_models_to_evaluate = {\n",
        "    \"BGE_Large_FT\": os.path.join(finetuned_embedding_models_folder, \"BGE_Large_FT\"),\n",
        "    \"MPNet_FT\": os.path.join(finetuned_embedding_models_folder, \"MPNet_FT\"),\n",
        "    \"E5_Large_FT\": os.path.join(finetuned_embedding_models_folder, \"E5_Large_FT\")\n",
        "}\n",
        "\n",
        "# Path to the folder containing all your fine-tuned cross-encoder models (Re-rankers)\n",
        "finetuned_cross_encoder_models_folder = os.path.join(data_folder, \"fine_tuned_models_hard_neg\")\n",
        "cross_encoder_models_to_evaluate = {\n",
        "    \"MiniLM_CrossEncoder\": os.path.join(finetuned_cross_encoder_models_folder, \"MiniLM_CrossEncoder\"),\n",
        "    \"MPNet_CrossEncoder\": os.path.join(finetuned_cross_encoder_models_folder, \"MPNet_CrossEncoder\"),\n",
        "    \"MSMarco_CrossEncoder\": os.path.join(finetuned_cross_encoder_models_folder, \"MSMarco_CrossEncoder\"),\n",
        "    \"BERT_CrossEncoder\": os.path.join(finetuned_cross_encoder_models_folder, \"BERT_CrossEncoder\")\n",
        "}\n",
        "\n",
        "# Path to the graph and test questions\n",
        "graph_path = os.path.join(data_folder, \"graph.gpickle\")\n",
        "test_set_path = os.path.join(data_folder, \"ObliQA_MultiPassage_test.json\")\n",
        "\n",
        "# --- Pipeline Parameters ---\n",
        "K_INITIAL = 100\n",
        "K_GRAPH = 25\n",
        "K_FINAL = 20\n",
        "PARENT_BONUS = 0.01\n",
        "CITATION_BONUS = 0.02\n",
        "\n",
        "# --- Load Static Components (that don't change between loops) ---\n",
        "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "print(f\"Using device: {device}\")\n",
        "\n",
        "print(\"Loading graph and test data...\")\n",
        "with open(graph_path, \"rb\") as f:\n",
        "    G = pickle.load(f)\n",
        "with open(test_set_path, \"r\", encoding=\"utf-8\") as f:\n",
        "    test_data = json.load(f)\n",
        "\n",
        "# Get all passage UIDs and text from the graph\n",
        "all_passage_uids = [node_id for node_id, data in G.nodes(data=True) if data.get(\"type\") == \"Passage\"]\n",
        "corpus = [G.nodes[uid].get(\"text\", \"\") for uid in all_passage_uids]\n",
        "\n",
        "# Build the BM25 index once\n",
        "print(\"Building BM25 index...\")\n",
        "tokenized_corpus = [doc.split(\" \") for doc in corpus]\n",
        "bm25 = BM25Okapi(tokenized_corpus)\n",
        "\n",
        "print(\"All static components loaded successfully.\")\n",
        "\n",
        "# --- Reciprocal Rank Fusion (RRF) Function ---\n",
        "def reciprocal_rank_fusion(ranked_lists, k=60):\n",
        "    fused_scores = {}\n",
        "    for doc_list in ranked_lists:\n",
        "        for i, doc_uid in enumerate(doc_list):\n",
        "            rank = i + 1\n",
        "            if doc_uid not in fused_scores:\n",
        "                fused_scores[doc_uid] = 0\n",
        "            fused_scores[doc_uid] += 1 / (k + rank)\n",
        "\n",
        "    reranked_results = sorted(fused_scores.items(), key=lambda x: x[1], reverse=True)\n",
        "    return [doc for doc, score in reranked_results]\n",
        "\n",
        "# --- Main Evaluation Loop ---\n",
        "all_evaluation_results = []\n",
        "\n",
        "# Outer loop: Iterate through each fine-tuned embedding model (Retriever)\n",
        "for retriever_name, retriever_path in embedding_models_to_evaluate.items():\n",
        "    print(\"\\n\" + \"=\"*80)\n",
        "    print(f\"--- Preparing Retriever: {retriever_name} ---\")\n",
        "    print(\"=\"*80)\n",
        "\n",
        "    # --- 1. Generate Embeddings with the current Retriever ---\n",
        "    print(f\"Loading fine-tuned embedding model from: {retriever_path}\")\n",
        "    embedding_model = SentenceTransformer(retriever_path, device=device)\n",
        "\n",
        "    print(\"Generating new passage embeddings...\")\n",
        "    embeddings = embedding_model.encode(corpus, show_progress_bar=True, batch_size=16)\n",
        "    embeddings_tensor = torch.tensor(embeddings).to(device)\n",
        "\n",
        "    # Inner loop: Iterate through each fine-tuned cross-encoder model (Re-ranker)\n",
        "    for reranker_name, reranker_path in cross_encoder_models_to_evaluate.items():\n",
        "        print(\"\\n\" + \"-\"*80)\n",
        "        print(f\"--- Evaluating Pipeline: [Retriever: {retriever_name}] + [Re-ranker: {reranker_name}] ---\")\n",
        "        print(\"-\" * 80)\n",
        "\n",
        "        # --- Load the current Re-ranker ---\n",
        "        print(f\"Loading Cross-Encoder model from: {reranker_path}\")\n",
        "        cross_encoder_tokenizer = AutoTokenizer.from_pretrained(reranker_path)\n",
        "        cross_encoder_model = AutoModelForSequenceClassification.from_pretrained(reranker_path).to(device)\n",
        "        cross_encoder_model.eval()\n",
        "\n",
        "        # --- 2. Run the Full Hybrid Pipeline ---\n",
        "        all_retrieved_results = {}\n",
        "        print(f\"Running hybrid pipeline for {len(test_data)} questions...\")\n",
        "        for q in tqdm(test_data, desc=f\"Processing Queries for {retriever_name} + {reranker_name}\"):\n",
        "            qid = q[\"QuestionID\"]\n",
        "            question = q[\"Question\"]\n",
        "\n",
        "            # Stage 1: Hybrid Retrieval\n",
        "            query_embedding = embedding_model.encode(question, convert_to_tensor=True)\n",
        "            cos_scores = util.pytorch_cos_sim(query_embedding, embeddings_tensor)[0]\n",
        "            semantic_results = torch.topk(cos_scores, k=min(K_INITIAL, len(all_passage_uids)))\n",
        "            semantic_uids = [all_passage_uids[i] for i in semantic_results.indices.tolist()]\n",
        "\n",
        "            tokenized_query = question.split(\" \")\n",
        "            bm25_scores = bm25.get_scores(tokenized_query)\n",
        "            top_bm25_indices = np.argsort(bm25_scores)[::-1][:min(K_INITIAL, len(all_passage_uids))]\n",
        "            bm25_uids = [all_passage_uids[i] for i in top_bm25_indices]\n",
        "\n",
        "            fused_uids = reciprocal_rank_fusion([semantic_uids, bm25_uids])\n",
        "\n",
        "            uid_to_initial_score = {uid: score for uid, score in zip(semantic_uids, semantic_results.values.tolist())}\n",
        "\n",
        "            initial_candidates = []\n",
        "            for uid in fused_uids:\n",
        "                initial_candidates.append({\n",
        "                    \"internal_uid\": uid,\n",
        "                    \"initial_score\": uid_to_initial_score.get(uid, 0),\n",
        "                    \"graph_bonus\": 0.0\n",
        "                })\n",
        "\n",
        "            retrieved_uids_set = {cand[\"internal_uid\"] for cand in initial_candidates}\n",
        "\n",
        "            # Stage 2: Graph-Based Re-ranking\n",
        "            for i, cand in enumerate(initial_candidates):\n",
        "                current_uid = cand[\"internal_uid\"]\n",
        "                for parent_uid in G.predecessors(current_uid):\n",
        "                    if G.get_edge_data(parent_uid, current_uid, {}).get(\"type\") == \"PARENT_OF\":\n",
        "                        if parent_uid in retrieved_uids_set:\n",
        "                            initial_candidates[i][\"graph_bonus\"] += PARENT_BONUS\n",
        "                        break\n",
        "                for predecessor_uid in G.predecessors(current_uid):\n",
        "                    if G.get_edge_data(predecessor_uid, current_uid, {}).get(\"type\") == \"CITED_BY\":\n",
        "                        if predecessor_uid in retrieved_uids_set:\n",
        "                            initial_candidates[i][\"graph_bonus\"] += CITATION_BONUS\n",
        "\n",
        "            for cand in initial_candidates:\n",
        "                cand[\"graph_score\"] = cand[\"initial_score\"] + cand[\"graph_bonus\"]\n",
        "\n",
        "            graph_reranked = sorted(initial_candidates, key=lambda x: x[\"graph_score\"], reverse=True)\n",
        "\n",
        "            # Stage 3: Cross-Encoder Re-ranking\n",
        "            cross_encoder_candidates = graph_reranked[:K_GRAPH]\n",
        "\n",
        "            ce_input_pairs = [[question, G.nodes[cand[\"internal_uid\"]].get(\"text\", \"\")] for cand in cross_encoder_candidates]\n",
        "\n",
        "            with torch.no_grad():\n",
        "                # FIX: Explicitly set max_length to prevent runtime error with certain models\n",
        "                inputs = cross_encoder_tokenizer(ce_input_pairs, padding=True, truncation=True, max_length=512, return_tensors=\"pt\").to(device)\n",
        "                outputs = cross_encoder_model(**inputs)\n",
        "                scores = torch.softmax(outputs.logits, dim=1)[:, 1].cpu().numpy()\n",
        "\n",
        "            for i, cand in enumerate(cross_encoder_candidates):\n",
        "                cand[\"final_score\"] = scores[i]\n",
        "\n",
        "            final_reranked = sorted(cross_encoder_candidates, key=lambda x: x[\"final_score\"], reverse=True)\n",
        "\n",
        "            final_results = []\n",
        "            for cand in final_reranked[:K_FINAL]:\n",
        "                uid = cand[\"internal_uid\"]\n",
        "                node = G.nodes[uid]\n",
        "                final_results.append({\n",
        "                    \"uid\": f\"{node.get('document_id', '')}|||{node.get('passage_id', '')}\",\n",
        "                    \"score\": float(cand[\"final_score\"])\n",
        "                })\n",
        "            all_retrieved_results[qid] = final_results\n",
        "\n",
        "        # --- 3. Evaluate the Results for the Current Combination ---\n",
        "        eval_folder = os.path.join(data_folder, \"evaluation_files\")\n",
        "        qrel_path = os.path.join(eval_folder, \"qrels.trec\")\n",
        "\n",
        "        qrel = {}\n",
        "        with open(qrel_path, \"r\", encoding=\"utf-8\") as f:\n",
        "            for line in f:\n",
        "                parts = line.strip().split()\n",
        "                if len(parts) >= 4:\n",
        "                    qid, _, uid, rel = parts[0], parts[1], \" \".join(parts[2:-1]), parts[-1]\n",
        "                    qrel.setdefault(qid, {})[uid] = int(rel)\n",
        "\n",
        "        evaluator = pytrec_eval.RelevanceEvaluator(qrel, {\"recall\", \"map_cut\", \"ndcg_cut\"})\n",
        "\n",
        "        run = {qid: {p[\"uid\"]: p[\"score\"] for p in passages} for qid, passages in all_retrieved_results.items()}\n",
        "        results = evaluator.evaluate(run)\n",
        "\n",
        "        R_10, MAP_10, NDCG_10 = 0.0, 0.0, 0.0\n",
        "        num_queries = len(results)\n",
        "        for qid in results:\n",
        "            R_10 += results[qid].get(\"recall_10\", 0.0)\n",
        "            MAP_10 += results[qid].get(\"map_cut_10\", 0.0)\n",
        "            NDCG_10 += results[qid].get(\"ndcg_cut_10\", 0.0)\n",
        "\n",
        "        all_evaluation_results.append({\n",
        "            \"Model\": f\"Retriever: {retriever_name} | Re-ranker: {reranker_name}\",\n",
        "            \"Recall@10\": R_10 / num_queries,\n",
        "            \"MAP@10\": MAP_10 / num_queries,\n",
        "            \"nDCG@10\": NDCG_10 / num_queries\n",
        "        })\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000,
          "referenced_widgets": [
            "fcfdc15a85fa450fbbb8211e8d9c986d",
            "58879b517248413b95043db65d266249",
            "f1233bd0789342a68953ae685b79de25",
            "1f396c2fe6fd46bf9717528bc67fef36",
            "7009eb9f84d14499a1323477c85ed03e",
            "a80f5490bd6649ea84f8cf3b1ab8b6da",
            "b2186b45675249d79c67fd58f7b5f3fb",
            "aa2b708762b644a9bf8aec34d085938e",
            "4136b93e284740c585420be88c438b78",
            "13683102556e4754821c22b618864423",
            "472df0d3604d4a09aba723fa4e042e1f",
            "6545a3252b184ca0894659a0719005b5",
            "4a6a062aff6f4739bedf0b131fdc36b0",
            "803d566254d94e2ab06df2e07bbb3032",
            "e50822d6695d48b698ad613aec637019",
            "c63eb1b6e9ab433cb55b44559121540a",
            "303d8886154b4c078813c15b07fb0b9f",
            "8dbfefd9bf8b4d67abf08a472679e472",
            "30806cb2848641f5bd17f6858d6522ea",
            "d32231715d2c43e8b62122dc9ccce0f7",
            "5033a65b5bf94691b4a6e4562502f7de",
            "4a889416aaf24d2ca21d4ea7f3523174",
            "4e47384220d145edab7ef0eff52174af",
            "e22bb1a0d6f5445a9a9792f56d1982e3",
            "ac796a4aa6fa494d854dce86cac10998",
            "36e2268747ee4d56ba47c82e1ab9078f",
            "6a118a58fea64265af1eadd574744796",
            "5ebc4bee0ac8439185c6270df4d7059d",
            "a543617fb92a4b349762f46ce720648a",
            "b0e7c20d727147b38fe2715f31b7eb4f",
            "6ef061541e99459caadea1a19240c318",
            "90da97e95ca549cda9075939b9049abb",
            "6ac61483683a49be86fafb99d557b444"
          ]
        },
        "id": "2rgvlG71Xt5F",
        "outputId": "f093d4a8-9962-45ce-81d0-0e729b94f1d6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Using device: cuda\n",
            "Loading graph and test data...\n",
            "Building BM25 index...\n",
            "All static components loaded successfully.\n",
            "\n",
            "================================================================================\n",
            "--- Preparing Retriever: BGE_Large_FT ---\n",
            "================================================================================\n",
            "Loading fine-tuned embedding model from: /content/drive/MyDrive/Colab Notebooks/modeldatalocation/finetuned_embedding_models_hard_neg/BGE_Large_FT\n",
            "Generating new passage embeddings...\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Batches:   0%|          | 0/859 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "fcfdc15a85fa450fbbb8211e8d9c986d"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "--------------------------------------------------------------------------------\n",
            "--- Evaluating Pipeline: [Retriever: BGE_Large_FT] + [Re-ranker: MiniLM_CrossEncoder] ---\n",
            "--------------------------------------------------------------------------------\n",
            "Loading Cross-Encoder model from: /content/drive/MyDrive/Colab Notebooks/modeldatalocation/fine_tuned_models_hard_neg/MiniLM_CrossEncoder\n",
            "Running hybrid pipeline for 447 questions...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Processing Queries for BGE_Large_FT + MiniLM_CrossEncoder: 100%|██████████| 447/447 [01:20<00:00,  5.58it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "--------------------------------------------------------------------------------\n",
            "--- Evaluating Pipeline: [Retriever: BGE_Large_FT] + [Re-ranker: MPNet_CrossEncoder] ---\n",
            "--------------------------------------------------------------------------------\n",
            "Loading Cross-Encoder model from: /content/drive/MyDrive/Colab Notebooks/modeldatalocation/fine_tuned_models_hard_neg/MPNet_CrossEncoder\n",
            "Running hybrid pipeline for 447 questions...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Processing Queries for BGE_Large_FT + MPNet_CrossEncoder: 100%|██████████| 447/447 [03:11<00:00,  2.33it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "--------------------------------------------------------------------------------\n",
            "--- Evaluating Pipeline: [Retriever: BGE_Large_FT] + [Re-ranker: MSMarco_CrossEncoder] ---\n",
            "--------------------------------------------------------------------------------\n",
            "Loading Cross-Encoder model from: /content/drive/MyDrive/Colab Notebooks/modeldatalocation/fine_tuned_models_hard_neg/MSMarco_CrossEncoder\n",
            "Running hybrid pipeline for 447 questions...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Processing Queries for BGE_Large_FT + MSMarco_CrossEncoder: 100%|██████████| 447/447 [01:35<00:00,  4.69it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "--------------------------------------------------------------------------------\n",
            "--- Evaluating Pipeline: [Retriever: BGE_Large_FT] + [Re-ranker: BERT_CrossEncoder] ---\n",
            "--------------------------------------------------------------------------------\n",
            "Loading Cross-Encoder model from: /content/drive/MyDrive/Colab Notebooks/modeldatalocation/fine_tuned_models_hard_neg/BERT_CrossEncoder\n",
            "Running hybrid pipeline for 447 questions...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Processing Queries for BGE_Large_FT + BERT_CrossEncoder: 100%|██████████| 447/447 [02:42<00:00,  2.75it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "================================================================================\n",
            "--- Preparing Retriever: MPNet_FT ---\n",
            "================================================================================\n",
            "Loading fine-tuned embedding model from: /content/drive/MyDrive/Colab Notebooks/modeldatalocation/finetuned_embedding_models_hard_neg/MPNet_FT\n",
            "Generating new passage embeddings...\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Batches:   0%|          | 0/859 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "6545a3252b184ca0894659a0719005b5"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "--------------------------------------------------------------------------------\n",
            "--- Evaluating Pipeline: [Retriever: MPNet_FT] + [Re-ranker: MiniLM_CrossEncoder] ---\n",
            "--------------------------------------------------------------------------------\n",
            "Loading Cross-Encoder model from: /content/drive/MyDrive/Colab Notebooks/modeldatalocation/fine_tuned_models_hard_neg/MiniLM_CrossEncoder\n",
            "Running hybrid pipeline for 447 questions...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Processing Queries for MPNet_FT + MiniLM_CrossEncoder: 100%|██████████| 447/447 [01:16<00:00,  5.81it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "--------------------------------------------------------------------------------\n",
            "--- Evaluating Pipeline: [Retriever: MPNet_FT] + [Re-ranker: MPNet_CrossEncoder] ---\n",
            "--------------------------------------------------------------------------------\n",
            "Loading Cross-Encoder model from: /content/drive/MyDrive/Colab Notebooks/modeldatalocation/fine_tuned_models_hard_neg/MPNet_CrossEncoder\n",
            "Running hybrid pipeline for 447 questions...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Processing Queries for MPNet_FT + MPNet_CrossEncoder: 100%|██████████| 447/447 [03:15<00:00,  2.29it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "--------------------------------------------------------------------------------\n",
            "--- Evaluating Pipeline: [Retriever: MPNet_FT] + [Re-ranker: MSMarco_CrossEncoder] ---\n",
            "--------------------------------------------------------------------------------\n",
            "Loading Cross-Encoder model from: /content/drive/MyDrive/Colab Notebooks/modeldatalocation/fine_tuned_models_hard_neg/MSMarco_CrossEncoder\n",
            "Running hybrid pipeline for 447 questions...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Processing Queries for MPNet_FT + MSMarco_CrossEncoder: 100%|██████████| 447/447 [01:32<00:00,  4.82it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "--------------------------------------------------------------------------------\n",
            "--- Evaluating Pipeline: [Retriever: MPNet_FT] + [Re-ranker: BERT_CrossEncoder] ---\n",
            "--------------------------------------------------------------------------------\n",
            "Loading Cross-Encoder model from: /content/drive/MyDrive/Colab Notebooks/modeldatalocation/fine_tuned_models_hard_neg/BERT_CrossEncoder\n",
            "Running hybrid pipeline for 447 questions...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Processing Queries for MPNet_FT + BERT_CrossEncoder: 100%|██████████| 447/447 [02:45<00:00,  2.71it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "================================================================================\n",
            "--- Preparing Retriever: E5_Large_FT ---\n",
            "================================================================================\n",
            "Loading fine-tuned embedding model from: /content/drive/MyDrive/Colab Notebooks/modeldatalocation/finetuned_embedding_models_hard_neg/E5_Large_FT\n",
            "Generating new passage embeddings...\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Batches:   0%|          | 0/859 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "4e47384220d145edab7ef0eff52174af"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "--------------------------------------------------------------------------------\n",
            "--- Evaluating Pipeline: [Retriever: E5_Large_FT] + [Re-ranker: MiniLM_CrossEncoder] ---\n",
            "--------------------------------------------------------------------------------\n",
            "Loading Cross-Encoder model from: /content/drive/MyDrive/Colab Notebooks/modeldatalocation/fine_tuned_models_hard_neg/MiniLM_CrossEncoder\n",
            "Running hybrid pipeline for 447 questions...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Processing Queries for E5_Large_FT + MiniLM_CrossEncoder: 100%|██████████| 447/447 [01:19<00:00,  5.60it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "--------------------------------------------------------------------------------\n",
            "--- Evaluating Pipeline: [Retriever: E5_Large_FT] + [Re-ranker: MPNet_CrossEncoder] ---\n",
            "--------------------------------------------------------------------------------\n",
            "Loading Cross-Encoder model from: /content/drive/MyDrive/Colab Notebooks/modeldatalocation/fine_tuned_models_hard_neg/MPNet_CrossEncoder\n",
            "Running hybrid pipeline for 447 questions...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Processing Queries for E5_Large_FT + MPNet_CrossEncoder: 100%|██████████| 447/447 [03:09<00:00,  2.36it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "--------------------------------------------------------------------------------\n",
            "--- Evaluating Pipeline: [Retriever: E5_Large_FT] + [Re-ranker: MSMarco_CrossEncoder] ---\n",
            "--------------------------------------------------------------------------------\n",
            "Loading Cross-Encoder model from: /content/drive/MyDrive/Colab Notebooks/modeldatalocation/fine_tuned_models_hard_neg/MSMarco_CrossEncoder\n",
            "Running hybrid pipeline for 447 questions...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Processing Queries for E5_Large_FT + MSMarco_CrossEncoder: 100%|██████████| 447/447 [01:34<00:00,  4.74it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "--------------------------------------------------------------------------------\n",
            "--- Evaluating Pipeline: [Retriever: E5_Large_FT] + [Re-ranker: BERT_CrossEncoder] ---\n",
            "--------------------------------------------------------------------------------\n",
            "Loading Cross-Encoder model from: /content/drive/MyDrive/Colab Notebooks/modeldatalocation/fine_tuned_models_hard_neg/BERT_CrossEncoder\n",
            "Running hybrid pipeline for 447 questions...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Processing Queries for E5_Large_FT + BERT_CrossEncoder: 100%|██████████| 447/447 [02:40<00:00,  2.79it/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# --- Final Comparison ---\n",
        "print(\"\\n\" + \"=\"*80)\n",
        "print(\"--- FINAL MODEL PERFORMANCE COMPARISON ---\")\n",
        "print(\"=\"*80)\n",
        "\n",
        "df_results = pd.DataFrame(all_evaluation_results)\n",
        "df_results = df_results.sort_values(by=\"MAP@10\", ascending=False)\n",
        "\n",
        "print(df_results.to_string(index=False, float_format=\"%.4f\"))\n",
        "\n",
        "final_comparison_path = os.path.join(data_folder, \"final_model_combination_comparison.csv\")\n",
        "df_results.to_csv(final_comparison_path, index=False)\n",
        "print(f\"\\n📁 Final comparison saved to: {final_comparison_path}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_DXINNNYXx0n",
        "outputId": "ae06eb4b-d18c-4718-8d7f-62cfce12f9be"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "================================================================================\n",
            "--- FINAL MODEL PERFORMANCE COMPARISON ---\n",
            "================================================================================\n",
            "                                                    Model  Recall@10  MAP@10  nDCG@10\n",
            "   Retriever: E5_Large_FT | Re-ranker: MPNet_CrossEncoder     0.4488  0.3453   0.4317\n",
            "      Retriever: MPNet_FT | Re-ranker: MPNet_CrossEncoder     0.4363  0.3377   0.4217\n",
            "  Retriever: E5_Large_FT | Re-ranker: MiniLM_CrossEncoder     0.4457  0.3374   0.4241\n",
            "    Retriever: E5_Large_FT | Re-ranker: BERT_CrossEncoder     0.4560  0.3351   0.4236\n",
            "  Retriever: BGE_Large_FT | Re-ranker: MPNet_CrossEncoder     0.4416  0.3345   0.4197\n",
            "     Retriever: MPNet_FT | Re-ranker: MiniLM_CrossEncoder     0.4336  0.3312   0.4165\n",
            " Retriever: BGE_Large_FT | Re-ranker: MiniLM_CrossEncoder     0.4333  0.3266   0.4119\n",
            "   Retriever: BGE_Large_FT | Re-ranker: BERT_CrossEncoder     0.4421  0.3230   0.4103\n",
            "       Retriever: MPNet_FT | Re-ranker: BERT_CrossEncoder     0.4347  0.3194   0.4066\n",
            " Retriever: E5_Large_FT | Re-ranker: MSMarco_CrossEncoder     0.4306  0.2752   0.3649\n",
            "Retriever: BGE_Large_FT | Re-ranker: MSMarco_CrossEncoder     0.4216  0.2751   0.3620\n",
            "    Retriever: MPNet_FT | Re-ranker: MSMarco_CrossEncoder     0.4255  0.2687   0.3590\n",
            "\n",
            "📁 Final comparison saved to: /content/drive/MyDrive/Colab Notebooks/modeldatalocation/final_model_combination_comparison.csv\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "## Import up sound alert dependencies\n",
        "from IPython.display import Audio, display\n",
        "\n",
        "def allDone():\n",
        "  display(Audio(url='https://sound.peal.io/ps/audios/000/000/537/original/woo_vu_luvub_dub_dub.wav', autoplay=True))\n",
        "## Insert whatever audio file you want above"
      ],
      "metadata": {
        "id": "aSusCtcaYQ93"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "allDone()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 75
        },
        "id": "ryDyA-_AYSnT",
        "outputId": "0b8328e9-ba8e-4c4f-b407-c05bb3d5c0a2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.lib.display.Audio object>"
            ],
            "text/html": [
              "\n",
              "                <audio  controls=\"controls\" autoplay=\"autoplay\">\n",
              "                    <source src=\"https://sound.peal.io/ps/audios/000/000/537/original/woo_vu_luvub_dub_dub.wav\" type=\"audio/x-wav\" />\n",
              "                    Your browser does not support the audio element.\n",
              "                </audio>\n",
              "              "
            ]
          },
          "metadata": {}
        }
      ]
    }
  ]
}